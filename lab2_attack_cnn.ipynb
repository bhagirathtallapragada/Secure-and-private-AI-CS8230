{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2-attack_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagirathtallapragada/Secure-and-private-AI-CS8230/blob/main/lab2_attack_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1IIenRzV7Gv"
      },
      "source": [
        "# Attacking a CNN\n",
        "\n",
        "The CNN is vulnerable to adversarial examples as ![adv example](https://www.tensorflow.org/tutorials/generative/images/adversarial_example.png)\n",
        "\n",
        "In this exercise we will train a CNN to distinguish between instances of handwritten `0` and instances of handwritten `1`. We will be using `PyTorch` to do this.  \n",
        "\n",
        "Once we have a trained classifier, we will create adversarial examples from scratch using `ART`\n",
        "\n",
        "This is adopted from https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:10.840140Z",
          "start_time": "2021-09-20T18:59:10.789703Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DliMiT3jpciO",
        "outputId": "7d1d1f6a-f15f-4b20-c1a5-540b579c5d20"
      },
      "source": [
        "# some configurations for jupyter notebook\n",
        "%config Completer.use_jedi = False\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:12.977893Z",
          "start_time": "2021-09-20T18:59:11.491488Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhoEjgYmWJ0E",
        "scrolled": true,
        "outputId": "8a7f474d-99d1-4c45-e1b4-617c5092cb3a"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: numba~=0.53.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (0.53.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba~=0.53.1->adversarial-robustness-toolbox) (0.36.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:13.946374Z",
          "start_time": "2021-09-20T18:59:12.981641Z"
        },
        "id": "iIH4d-w4V7G7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIL2ziyzV7G_"
      },
      "source": [
        "The MNIST dataset contains data for all digits.\n",
        "\n",
        "We need to normalize the data. Here, we use the API from `ART`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3nYU03lV7HD"
      },
      "source": [
        "Load the actual data. It will load the data as numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:17.725807Z",
          "start_time": "2021-09-20T18:59:16.771840Z"
        },
        "id": "CMKzVNfRV7HA"
      },
      "source": [
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:19.612010Z",
          "start_time": "2021-09-20T18:59:18.723730Z"
        },
        "id": "tQcryxiipciS"
      },
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# Step 1a: Swap axes to PyTorch's NCHW format\n",
        "\n",
        "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
        "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:21.226435Z",
          "start_time": "2021-09-20T18:59:21.191616Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgM6JaYnpciT",
        "outputId": "c4ba0dd9-e372-4a65-b652-f901680cad07"
      },
      "source": [
        "print(type(x_train))\n",
        "print(x_train.shape, x_test.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(60000, 1, 28, 28) (10000, 1, 28, 28) (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d64xNkKdV7HX"
      },
      "source": [
        "We are using a very simple CNN. This network can be used to distinguish between all 10 classes with very high accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:59:27.699281Z",
          "start_time": "2021-09-20T18:59:27.651774Z"
        },
        "id": "GMjW64ADV7HY"
      },
      "source": [
        "# define the classifier\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
        "        self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
        "        self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4 * 4 * 10)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCpa8YxTpciV"
      },
      "source": [
        "Then, we initialize a model and train with the cross-entropy loss.\n",
        "\n",
        "To simplify the training code, we use the wrapper `PyTorchClassifier` from `ART` to train the model. See https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:24.768984Z",
          "start_time": "2021-09-20T19:00:13.492134Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ros3aiSpciV",
        "outputId": "48c313ae-1186-4d69-8037-7f02b048ca58"
      },
      "source": [
        "# Step 2: Create the model\n",
        "\n",
        "model = Net()\n",
        "\n",
        "# Step 2a: Define the loss function and the optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "\n",
        "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# the final accuracy should > 95%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples: 98.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:24.799098Z",
          "start_time": "2021-09-20T19:00:24.771574Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UdAnhnrfpciW"
      },
      "source": [
        "# the device(cpu/gpu) of the model\n",
        "\n",
        "device = next(model.parameters()).device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn0dNIotIQ_n"
      },
      "source": [
        "Let's get to the actual attack. First, we pick a sample that we want to perturb. After that we will be implementing our own FGSM attack. \n",
        "\n",
        "The attack is fairly simple. It consists of the following steps: \n",
        "\n",
        "1.   Compute the loss of the original sample\n",
        "2.   Calculate the gradient of the loss w.r.t the input \n",
        "3.   Take the sign of the gradient and add a fraction episilon to the input, namely $x + \\epsilon sign(\\nabla_x J(x, y))$\n",
        "\n",
        "Epsilon controlls the strenght of the pertubation.\n",
        "\n",
        "First, we select a sample to visualize it and output the model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:25.184151Z",
          "start_time": "2021-09-20T19:00:24.800964Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "DVSPLCc1pciX",
        "outputId": "2bc54a02-8d4e-439c-ff2d-b0c41d9c4041"
      },
      "source": [
        "\n",
        "#chose a sample to pertubate\n",
        "sample_ind = 25 # chosen by totaly random dice roll\n",
        "\n",
        "# picking a test sample\n",
        "sample = x_test[ sample_ind, : ]\n",
        "\n",
        "print( sample.shape )\n",
        "\n",
        "# plot the first instance in the traning set\n",
        "plt.imshow( sample.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n",
        "\n",
        "# why this reshaping?\n",
        "t_sample = torch.FloatTensor(sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ).to(device)\n",
        "pred_prob = F.softmax(model( t_sample ), dim=1)\n",
        "\n",
        "logits = classifier.predict( sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) )\n",
        "\n",
        "print( 'output for the test samples:\\n', logits )\n",
        "print( 'class prediction for the test samples:\\n', pred_prob.detach() )\n",
        "print( 'predicted as', np.argmax( logits , axis=1) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output for the test samples:\n",
            " [[ 10.334558   -19.12136     -4.955989    -6.1870327   -2.4843483\n",
            "   -6.8007627   -1.9237723   -3.0695798   -5.9716487   -0.13333023]]\n",
            "class prediction for the test samples:\n",
            " tensor([[9.9996e-01, 1.6123e-13, 2.2876e-07, 6.6796e-08, 2.7090e-06, 3.6158e-08,\n",
            "         4.7452e-06, 1.5088e-06, 8.2849e-08, 2.8434e-05]])\n",
            "predicted as [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOL5M8DbpciX"
      },
      "source": [
        "Since `ART` loads data as numpy array, we create variables as PyTorch Tensor for convenience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:56.753950Z",
          "start_time": "2021-09-20T19:00:56.724948Z"
        },
        "id": "i0UmjWGBpciY"
      },
      "source": [
        "\n",
        "t_sample = torch.FloatTensor(sample.reshape( (1, sample.shape[ 0 ], sample.shape[ 1 ], sample.shape[ 2 ]) ) ).to(device)\n",
        "\n",
        "#reshape for?\n",
        "one_hot_y = torch.LongTensor( y_test[ sample_ind, : ].reshape( ( 1, -1 ) ) )\n",
        "t_y = torch.argmax(one_hot_y, dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3Hky6CpciY"
      },
      "source": [
        "Construct adversarial examples from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:00:58.830194Z",
          "start_time": "2021-09-20T19:00:58.627458Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "jytjebmapciY",
        "outputId": "2fce7fe6-8542-40e5-df1a-c607d86b57a7"
      },
      "source": [
        "# constructing adversarial examples\n",
        "######################\n",
        "# fill in the blanks #\n",
        "######################\n",
        "\n",
        "eps = 0.2 # allowed maximum modification\n",
        "\n",
        "# compute logits\n",
        "\n",
        "logits =  model(t_sample) #??? t_sample ??? # \n",
        "print(logits)\n",
        "\n",
        "# compute the cross entropy loss of our original sample\n",
        "\n",
        "loss = nn.CrossEntropyLoss()(logits, t_y)  #logits, t_y ???\n",
        "print(loss)\n",
        "\n",
        "# get the gradient wrt to the input. \n",
        "# there are two ways to compute gradients. \n",
        "\n",
        "grads = torch.autograd.grad( loss, [t_sample] )\n",
        "print(grads.shape)\n",
        "\n",
        "# # You may see an error `RuntimeError: One of the differentiated Tensors does not require grad`\n",
        "# # What does it mean? and how to solve it?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 10.3346, -19.1214,  -4.9560,  -6.1870,  -2.4843,  -6.8008,  -1.9238,\n",
            "          -3.0696,  -5.9716,  -0.1333]], grad_fn=<AddmmBackward>)\n",
            "tensor(3.8027e-05, grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6fc66160fa8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# there are two ways to compute gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt_sample\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    226\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    227\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors does not require grad"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1vEH6hNpciY"
      },
      "source": [
        "It's caused by the mechanism of PyTorch.\n",
        "\n",
        "By default, only model's parameters will compute/require gradients.\n",
        "\n",
        "Now, we need to let the input data require gradients. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooA8fm-9ebFE"
      },
      "source": [
        "# x+ϵsign(∇xJ(x,y))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:06.538188Z",
          "start_time": "2021-09-20T19:02:06.405536Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "RovKr9sKIQgh",
        "outputId": "5f27fb46-12e1-44a0-bbba-06954b85444c"
      },
      "source": [
        "# constructing adversarial examples\n",
        "######################\n",
        "# fill in the blanks #\n",
        "######################\n",
        "\n",
        "eps = 1 # allowed maximum modification and increase it until it's misclassified\n",
        "\n",
        "# Set the data require gradients\n",
        "\n",
        "t_sample.requires_grad = True\n",
        "\n",
        "# compute logits\n",
        "\n",
        "logits = model(t_sample) #??? t_sample ???\n",
        "\n",
        "# compute the cross entropy  loss of our original sample\n",
        "\n",
        "loss = nn.CrossEntropyLoss()(logits, t_y) #???  logits, t_y ???\n",
        "\n",
        "# get the gradient wrt to the input.\n",
        "\n",
        "grads = torch.autograd.grad( loss, [t_sample] )[0]\n",
        "\n",
        "# make sure you get the correct gradients\n",
        "print(grads.shape)\n",
        "\n",
        "# calculate the pertubation\n",
        "\n",
        "perturbation = eps*torch.sign(grads) #??? grads ???\n",
        "\n",
        "# apply pertubation, x_adv = x + \\epsilon sign(\\nabla_x J(x, y))\n",
        "\n",
        "x_adv = t_sample + perturbation * eps\n",
        "\n",
        "# now that we have the adversarial examples\n",
        "# get the prediction result and print the adversarial example\n",
        "\n",
        "\n",
        "print( 'our adversarial example' )\n",
        "print( x_adv.shape )\n",
        "print( 'logits for our sample: \\t\\n', logits )\n",
        "\n",
        "# class prediction for the adverserial sample\n",
        "pred_prob = F.softmax(model( x_adv), dim=1)\n",
        "\n",
        "print( 'class prediction for our sample: \\t\\n', pred_prob )\n",
        "\n",
        "print( 'predicted as', torch.argmax(pred_prob, dim=1 ) )\n",
        "# increase eps until it's misclassified\n",
        "\n",
        "plt.imshow( x_adv.cpu().detach().numpy().reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "our adversarial example\n",
            "torch.Size([1, 1, 28, 28])\n",
            "logits for our sample: \t\n",
            " tensor([[ 10.3346, -19.1214,  -4.9560,  -6.1870,  -2.4843,  -6.8008,  -1.9238,\n",
            "          -3.0696,  -5.9716,  -0.1333]], grad_fn=<AddmmBackward>)\n",
            "class prediction for our sample: \t\n",
            " tensor([[4.2025e-06, 1.3665e-04, 9.9908e-01, 3.6285e-06, 9.8747e-06, 4.4386e-09,\n",
            "         1.9984e-09, 5.9722e-04, 1.6426e-04, 1.6507e-09]],\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "predicted as tensor([2])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azepEwpTewML"
      },
      "source": [
        "The FGSM is one of the most simple attacks.\n",
        "As we can see, results are not very convincing since the perturbation is perceptible.\n",
        "We can improve on it by making it iterative. \n",
        "\n",
        "Using the code from above, create an iterative version of FGSM that calculates a new perturbation for ever iteration and stops once it achieve misclassifaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:19.050472Z",
          "start_time": "2021-09-20T19:02:18.886103Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "mOHo8eQ0gS4F",
        "outputId": "936b5d36-63f6-4f31-ba15-9862f49dceb1"
      },
      "source": [
        "epsilon = 0.005\n",
        "iterations = 10\n",
        "\n",
        "x_adv = t_sample.detach().clone()\n",
        "x_adv.requires_grad = True\n",
        "\n",
        "for i in range(iterations):\n",
        "    # your code here\n",
        "\n",
        "    # compute logits\n",
        "    logits = model(t_sample)\n",
        "\n",
        "\n",
        "    # compute the loss of our original sample\n",
        "    loss = nn.CrossEntropyLoss()(logits, t_y) \n",
        "\n",
        "\n",
        "    # get the gradient wrt to the input.\n",
        "    grads = torch.autograd.grad( loss, [t_sample] )[0]    \n",
        "\n",
        "\n",
        "    # calculate the pertubation\n",
        "    perturbation = eps*torch.sign(grads)\n",
        "\n",
        "\n",
        "    # apply pertubation\n",
        "    x_adv = t_sample + perturbation * eps\n",
        "    print(torch.argmax( pred_prob, dim=1)[0],t_y)\n",
        "    if torch.argmax( pred_prob, dim=1)[0] != t_y:\n",
        "        break\n",
        "\n",
        "    \n",
        "print( 'our adversarial example' )\n",
        "print( x_adv.shape )\n",
        "\n",
        "print( 'logits for our sample: \\t\\n', logits )\n",
        "\n",
        "pred_prob = F.softmax(model(x_adv), dim=1)\n",
        "\n",
        "print( 'class prediction for our sample: \\t\\n', pred_prob )\n",
        "\n",
        "print( 'predicted as', torch.argmax(pred_prob, dim=1) )\n",
        "plt.imshow( x_adv.cpu().detach().numpy().reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2) tensor([0])\n",
            "our adversarial example\n",
            "torch.Size([1, 1, 28, 28])\n",
            "logits for our sample: \t\n",
            " tensor([[ 10.3346, -19.1214,  -4.9560,  -6.1870,  -2.4843,  -6.8008,  -1.9238,\n",
            "          -3.0696,  -5.9716,  -0.1333]], grad_fn=<AddmmBackward>)\n",
            "class prediction for our sample: \t\n",
            " tensor([[4.2025e-06, 1.3665e-04, 9.9908e-01, 3.6285e-06, 9.8747e-06, 4.4386e-09,\n",
            "         1.9984e-09, 5.9722e-04, 1.6426e-04, 1.6507e-09]],\n",
            "       grad_fn=<SoftmaxBackward>)\n",
            "predicted as tensor([2])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VszDZ1p6V7Hc"
      },
      "source": [
        "Let's use `ART` library to do the actual attack.\n",
        "\n",
        "We will also use the FGSM attack to generate an adversarial example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:36.178871Z",
          "start_time": "2021-09-20T19:02:33.620048Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lom_r6brpcia",
        "outputId": "dfd30f90-169e-45c4-f2f7-4cdf6cd71dd4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = accuracy_score(np.argmax(y_test,axis=1),np.argmax( predictions , axis=1))\n",
        "print(\"Accuracy on clean test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "# your code here\n",
        "# attacker = FastGradientMethod(estimator=classifier, eps=1, targeted=True)\n",
        "attack =  FastGradientMethod(estimator=classifier, eps=0.2, targeted=True)\n",
        "x_test_adv = attack.generate(x=x_test, y=np.argmax(y_test,axis=1))\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(x=x_test_adv)\n",
        "accuracy = accuracy_score(np.argmax(y_test,axis=1),np.argmax( predictions , axis=1))\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on clean test examples: 98.26%\n",
            "Accuracy on adversarial test examples: 99.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:02:39.628928Z",
          "start_time": "2021-09-20T19:02:39.493565Z"
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "xH_y5mdVpcia",
        "outputId": "049faef1-0631-4a07-9121-9a9c4e490cb1"
      },
      "source": [
        "# Visualize one example\n",
        "x_test_adv = attacker.generate(x=x_test[25:26],y)\n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_test_adv ) )\n",
        "\n",
        "# print( 'predicted as', np.argmax(x_test_adv) )\n",
        "\n",
        "plt.imshow( x_test_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-7a58a6b315e5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    x_test_adv = attacker.generate(x=x_test[25:26],y)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwngpuZCpcib"
      },
      "source": [
        "You can see that it's much simpler than we write it from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMRrmSkfpcib"
      },
      "source": [
        "You can check it from https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/get_started_pytorch.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKJQIF24Y91W"
      },
      "source": [
        "We have seen that FGSM does not do a great job of producing adversarial examples when work with 0 and 1. Update the code above work on all 10 digits and try for a number of 0 instance what class they get transformed into in an untargeted attack.\n",
        "Alternativley pick a pair of numbers that you think are closer to each orther and the FGSM attack should work better with.\n",
        "\n",
        "\n",
        "`ART` provides more attacks than the once introduced above. Try any other attacks from the official documents.\n",
        "\n",
        "You can find more information on the attacks here: https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Attacks, for example, the PGD attack(https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/attacks/evasion.html#projected-gradient-descent-pgd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T19:03:09.706790Z",
          "start_time": "2021-09-20T19:02:44.470933Z"
        },
        "id": "uvZ3hfrNcp9i"
      },
      "source": [
        "# your code here\n",
        "\n",
        "# Evaluate\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = \n",
        "print(\"Accuracy on clean test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "from art.attacks.evasion import ???\n",
        "\n",
        "x_test_adv = \n",
        "\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy =  \n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Visualize one example\n",
        "x_test_adv =  \n",
        "print( 'logits for our sample: \\t\\n', classifier.predict( x_test_adv ) )\n",
        "\n",
        "print( 'predicted as',  )\n",
        "\n",
        "plt.imshow( x_test_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
        "plt.axis( 'off' )\n",
        "plt.show( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-20T18:50:36.653185Z",
          "start_time": "2021-09-20T18:49:54.740Z"
        },
        "id": "-ebUgYkBpcic"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}